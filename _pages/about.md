---
permalink: /
title: "Shi Pu's Homepage"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Welcome! I am an assistant professor in the [School of Data Science](https://sds.cuhk.edu.cn/) at [The Chinese University of Hong Kong, Shenzhen](https://www.cuhk.edu.cn/).

Research Interests
---
Distributed optimization, machine learning, multi-agent networks.

See [here](https://pu-shi.github.io/lab/) for our research topics, and [here](https://pu-shi.github.io/publications/) for our publications.

Openings
---
We are always looking for self-motivated students with solid mathematical background and research interests in optimization, machine learning, distributed algorithms, game theory, etc.


Recent News
---
* June. 2025: Our paper, [Stochastic Push-Pull for Decentralized Nonconvex Optimization](https://arxiv.org/pdf/2506.07021) (with Runze You), is online!
* May. 2025: Our paper, [Decentralized Min-Max Optimization with Gradient Tracking](https://arxiv.org/pdf/2505.10631) (with Runze You and Kun Huang), is online!
* May. 2025: Our paper, [Asynchronous Decentralized SGD under Non-Convexity: A Block-Coordinate Descent Framework](https://arxiv.org/pdf/2505.10322) (with Yijie Zhou), is online!
* March. 2025: Our paper, [Distributed Learning over Arbitrary Topology: Linear Speed-Up with Polynomial Transient Time](https://arxiv.org/pdf/2503.16123?) (with Runze You), is online!
* March. 2025: Our paper, [Distributed Random Reshuffling Methods with Improved Convergence](https://arxiv.org/abs/2306.12037) (with Kun Huang and Linli Zhou), has been accepted for publication in IEEE Transactions on Automatic Control!
* February. 2025: Our paper, [An Accelerated Distributed Stochastic Gradient Method with Momentum](https://arxiv.org/pdf/2402.09714.pdf) (with Kun Huang and Angelia Nedić), has been accepted for publication in Mathematical Programming!
* February. 2025: I gave a talk titled "B-ary Tree Push-Pull Method for Distributed Optimization" at Anhui University. Thank Prof. Songsong Cheng for inviting!
* December. 2024: Congratulations to Kun Huang for passing the PhD defense!
* December. 2024: Our paper, [Distributed Normal Map-based Stochastic Proximal Gradient Methods over Networks](https://arxiv.org/pdf/2412.13054) (with Kun Huang and Angelia Nedić), is online!
* December. 2024: Our paper, [Linear Convergence Analysis of Single-loop Algorithm for Bilevel Optimization via Small-gain Theorem](https://arxiv.org/pdf/2412.00659) (with Jianhui Li, Jianqi Chen and Junfeng Wu), is online!
* November. 2024: I gave a talk titled "B-ary Tree Push-Pull Method for Distributed Optimization" at SUSTech. Thank Prof. Jin Zhang for inviting!
* September. 2024: Our paper, [CEDAS: A Compressed Decentralized Stochastic Gradient Method with Improved Convergence](https://ieeexplore.ieee.org/document/10700994) (with Kun Huang), has been accepted for publication in IEEE Transactions on Automatic Control as Full Paper!
* September. 2024: Our paper, [B-ary Tree Push-Pull Method is Provably Efficient for Decentralized Learning on Heterogeneous Data](https://arxiv.org/pdf/2404.05454.pdf) (with Runze You), has been accepted by NeurIPS 2024!
* August. 2024: Our paper, [A Robust Compressed Push-Pull Method for Decentralized Nonconvex Optimization](https://arxiv.org/pdf/2408.01727) (with Yiwei Liao, Zhuorui Li and Tsung-Hui Chang), is online!
* April. 2024: Our paper, [Distributed Stochastic Optimization under a General Variance Condition](https://arxiv.org/abs/2301.12677) (with Kun Huang and Xiao Li), has been accepted for publication in IEEE Transactions on Automatic Control as Full Paper!
* April. 2024: Our paper, [B-ary Tree Push-Pull Method is Provably Efficient for Decentralized Learning on Heterogeneous Data](https://arxiv.org/pdf/2404.05454.pdf) (with Runze You), is online!
* February. 2024: Our paper, [An Accelerated Distributed Stochastic Gradient Method with Momentum](https://arxiv.org/pdf/2402.09714.pdf) (with Kun Huang and Angelia Nedić), is online!
* December. 2023: Our paper, [Provably Accelerated Decentralized Gradient Method Over Unbalanced Directed Graphs](https://arxiv.org/pdf/2107.12065.pdf) (with Zhuoqing Song, Lei Shi and Ming Yan) has been accepted for publication in SIAM Journal on Optimization!
* August. 2023: I became an IEEE senior member.
* August. 2023: I gave a talk titled "Distributed Stochastic Gradient Methods over Networks" during The 14th International Conference on Numerical Optimization and Numerical Linear Algebra.
* July. 2023: Our paper, [A Linearly Convergent Robust Compressed Push-Pull Method for Decentralized Optimization](https://arxiv.org/abs/2303.07091) (with Yiwei Liao and Zhuorui Li), has been accepted by 2023 IEEE Conference on Decision and Control!
* Jun. 2023: Our new paper, [Distributed Random Reshuffling Methods with Improved Convergence](https://arxiv.org/abs/2306.12037) (with Linli Zhou and Kun Huang), is online!
* Jun. 2023: Our paper, [Optimal Gradient Tracking for Decentralized Optimization](https://arxiv.org/pdf/2110.05282.pdf) (with Zhuoqing Song, Lei Shi and Ming Yan) has been accepted for publication in Mathematical Programming!
* May. 2023: I gave an invited talk titled "Asymptotic Network Independence in Distributed Stochastic Gradient Methods" during MOS2023. Thank Prof. Xiangfeng Wang, Prof. Hongjin He and Prof. Wenxing Zhang for organizing!
* Mar. 2023: Our paper, [A Linearly Convergent Robust Compressed Push-Pull Method for Decentralized Optimization](https://arxiv.org/abs/2303.07091) (with Yiwei Liao and Zhuorui Li), is online!
* Mar. 2023: Our paper, [Distributed Random Reshuffling over Networks](https://arxiv.org/pdf/2112.15287.pdf) (with Kun Huang, Xiao Li, Andre Milzarek, and Junwen Qiu), has been accepted for publication in IEEE Transactions on Signal Processing!
* Jan. 2023: Our paper, [Distributed Stochastic Optimization under a General Variance Condition](https://arxiv.org/abs/2301.12677) (with Kun Huang and Xiao Li), is online!
* Jan. 2023: Our paper, [CEDAS: A Compressed Decentralized Stochastic Gradient Method with Improved Convergence](https://arxiv.org/abs/2301.05872) (with Kun Huang), is online!
