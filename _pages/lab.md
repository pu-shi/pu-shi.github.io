---
layout: archive
title: "MALO Lab"
permalink: /lab/
author_profile: true
---

In the Multi-Agent Learning and Optimization (MALO) Lab, we study distributed algorithms for learning and optimization over multi-agent networks.
Specifically, we design the rules for a group of autonomous agents, each with **local information**, to collaboratively achieve a global objective through **local computation** and **local communication**. Applications of our research include large-scale distributed machine learning, resource allocation in networks, multi-robot coordination, decentralized estimation, among others.
Our research is interdisciplinary in nature and spans areas including **network science**, **optimization**, **control theory**, and **machine learning**.

## Elements of Distributed Learning and Optimization

### Multi-Agent Networks
Computer networks, social networks, sensor networks, etc.

### Computing Architecture
![Centralized Architecture](/images/tpo_cen.png){:height="30%" width="30%"}
![Decentralized Architecture](/images/tpo_dec.png){:height="30%" width="30%"}  
The above shows two typical computing architectures for distributed computation: centralized (left) vs decentralized (right). MALO Lab focuses on the **decentralized architecture** which requires no central controller, enjoys more flexibility, robustness, and lower communication overhead.

### Problem settings:
* Objective functions and constraints: convex vs nonconvex, unconstrained vs constrained, simple vs composite functions.  
* Network topology: undirected vs directed, time-varying.  
* Communication: delays, message losses, Byzantine attacks.

### Algorithms:  
* Optimization: (stochastic) gradients, zeroth-order, higher-order, dual methods, ADMM.  
* Coordination: synchronous, gossip, broadcast, fully asynchronous.  
* Communication: compression, event-triggered.  
* Robustness: tolerant to message losses, node failures, etc.


Current Projects
---
### Asymptotic Network Independence in Distributed Optimization

This p

### Communication-Efficient Decentralized Learning Methods
---

### Project: Distributed Optimization over General Directed Networks
---

Funding Support
---
The research of MALO Lab has been supported by Shenzhen Research Institute of Big Data, Shenzhen Institute of Artificial Intelligence and Robotics for Society, and National Natural Science Foundation of China.
